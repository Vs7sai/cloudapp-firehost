{
  "success": true,
  "data": {
    "topic": "docker",
    "difficulty": "pro",
    "questions": 
[
  {
    "id": 1,
    "text": "Explain Docker Swarm and container orchestration",
    "explanation": "Docker Swarm is Docker's native clustering and orchestration tool for managing multiple Docker hosts as a single virtual system.\n\nKey concepts:\n• Manager nodes: Control the swarm and orchestrate containers\n• Worker nodes: Run containers as assigned by managers\n• Services: Define how containers should run across the swarm\n• Tasks: Individual container instances\n• Load balancing: Automatic distribution of requests\n\nSwarm vs Kubernetes:\n• Swarm: Simpler, integrated with Docker, good for smaller deployments\n• Kubernetes: More features, larger ecosystem, better for complex deployments"
  },
  {
    "id": 2,
    "text": "What are Docker security best practices?",
    "explanation": "Docker security best practices:\n\n1. Image Security:\n• Use official base images\n• Scan images for vulnerabilities\n• Use minimal base images\n• Keep images updated\n\n2. Container Runtime:\n• Run as non-root user\n• Use read-only filesystems\n• Limit resource usage\n• Enable security profiles (AppArmor/SELinux)\n\n3. Network Security:\n• Use custom networks\n• Limit port exposure\n• Use secrets management\n• Enable TLS encryption\n\n4. Host Security:\n• Keep Docker daemon updated\n• Limit Docker daemon access\n• Use Docker Bench for Security\n• Monitor container behavior"
  },
  {
    "id": 3,
    "text": "How do you troubleshoot Docker performance issues?",
    "explanation": "Docker performance troubleshooting approach:\n\n1. Resource Monitoring:\n• docker stats: Real-time resource usage\n• docker system df: Disk space usage\n• docker system events: System events\n\n2. Common Issues:\n• Memory leaks in applications\n• Inefficient Dockerfile layers\n• Too many containers on single host\n• Network bottlenecks\n• Storage driver performance\n\n3. Optimization:\n• Use appropriate resource limits\n• Optimize application code\n• Use caching strategies\n• Choose right base images\n• Monitor with tools like Prometheus/Grafana\n• Use health checks for better orchestration"
  },
  {
    "id": 4,
    "text": "How do you investigate and fix a container consuming excessive resources causing performance issues?",
    "explanation": "Use `docker stats` and `docker inspect` to monitor and diagnose resource usage.\n\n**Investigation Steps:**\n1. Monitor real-time usage: `docker stats`\n2. Check resource limits: `docker inspect <container>`\n3. Review logs for OOM events: `docker logs <container>`\n4. Set appropriate limits if missing\n\n**Key Commands:**\n```bash\n# Monitor resource usage\ndocker stats my-app\n\n# Check current limits\ndocker inspect my-app | grep -E 'Memory|Cpu'\n\n# Set resource limits\ndocker run -d --cpus=\"0.5\" --memory=\"512m\" my-app\n```\n\n**Resolution:**\n• Set resource limits using `--cpus` and `--memory`\n• Use `resources` section in docker-compose.yml\n• Profile application to identify bottlenecks\n• Scale resources or distribute across hosts"
  },
  {
    "id": 5,
    "text": "How do you update a running container with minimal downtime?",
    "explanation": "Use a **blue/green deployment** strategy - run the new version alongside the old, verify health, then switch traffic.\n\n**Steps:**\n1. Pull new image: `docker pull my-app:new-version`\n2. Start new container on different port: `docker run -d -p 8080:80 --name my-app-new my-app:new-version`\n3. Verify health: `curl http://localhost:8080/health`\n4. Switch traffic (update load balancer or ports)\n5. Stop old container: `docker stop my-app-old`\n6. Remove old container: `docker rm my-app-old`\n\n**Rollback if needed:**\nIf new container fails health checks, stop it and keep the old one running.\n\n**Traffic Switching:**\n• With load balancer: Update config to point to new container\n• Without load balancer: Stop old, rename new to use original port"
  },
  {
    "id": 6,
    "text": "How do you securely manage secrets in Docker Compose without hardcoding them?",
    "explanation": "Use **Docker Compose's built-in secrets feature** to mount secrets as read-only files.\n\n**docker-compose.yml:**\n```yaml\nversion: '3.8'\nservices:\n  worker:\n    image: my-worker-image:latest\n    secrets:\n      - my_api_key\n    environment:\n      API_KEY_FILE: /run/secrets/my_api_key\n\nsecrets:\n  my_api_key:\n    file: ./api_key.txt\n```\n\n**How it works:**\n1. Create secret file on host: `./api_key.txt` (add to .gitignore)\n2. Define secret in compose file\n3. Mount to service using `secrets:` section\n4. Access in app via file path: `/run/secrets/my_api_key`\n\n**Benefits:**\n• No hardcoding in compose files\n• Read-only file mount (more secure than env vars)\n• Not visible via `docker inspect`\n• Runtime injection only"
  },
  {
    "id": 7,
    "text": "How do you set up real-time log streaming from containers?",
    "explanation": "Use `docker logs -f` for console output or configure logging drivers for external systems.\n\n**Console Streaming:**\n```bash\n# Follow single container logs\ndocker logs -f my-container\n\n# Follow compose service logs\ndocker compose logs -f web_app\n```\n\n**External Logging (Production):**\n```yaml\n# docker-compose.yml with syslog\nservices:\n  my-app:\n    image: my-app:latest\n    logging:\n      driver: syslog\n      options:\n        syslog-address: \"udp://localhost:514\"\n        tag: \"my-app-logs\"\n```\n\n**Available Drivers:**\n• `json-file` - Default, with rotation options\n• `syslog` - Send to syslog server\n• `fluentd` - Send to Fluentd\n• `awslogs` - Send to CloudWatch\n• `gcp-logging` - Send to Google Cloud"}
  },
  {
    "id": 8,
    "text": "How do you backup a Docker named volume without accessing daemon storage?",
    "explanation": "Use a temporary container that mounts both the volume and a backup destination.\n\n**Backup Command:**\n```bash\n# Create backup directory\nmkdir -p ./backups\n\n# Run temporary container to create backup\ndocker run --rm \\\n  -v my_app_data:/data_to_backup \\\n  -v $(pwd)/backups:/backup_dest \\\n  ubuntu:latest \\\n  tar -czvf /backup_dest/backup_$(date +%Y%m%d).tar.gz -C /data_to_backup .\n```\n\n**How it works:**\n1. Temporary container mounts the named volume as `/data_to_backup`\n2. Host backup directory mounted as `/backup_dest`\n3. `tar` command creates compressed archive\n4. Container auto-removes with `--rm` flag\n\n**Restore:**\n```bash\ndocker run --rm \\\n  -v my_app_data:/data_to_restore \\\n  -v $(pwd)/backups:/backup_source \\\n  ubuntu:latest \\\n  tar -xzvf /backup_source/backup.tar.gz -C /data_to_restore\n```"
  },
  {
    "id": 9,
    "text": "How do you configure a container to access the host's Docker daemon for CI/CD?",
    "explanation": "Mount the Docker socket from host to container to enable Docker-out-of-Docker.\n\n**Basic Setup:**\n```bash\n# Interactive Docker CLI access\ndocker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock docker:latest sh\n\n# CI/CD agent\ndocker run -d -v /var/run/docker.sock:/var/run/docker.sock my-ci-agent\n```\n\n**How it works:**\n• Mount `/var/run/docker.sock:/var/run/docker.sock`\n• Container can execute docker commands on host daemon\n• Use official `docker:latest` image for Docker CLI\n\n**⚠️ Security Warning:**\nThis grants **root-level access** to the Docker host. If container is compromised, attacker has full host control.\n\n**Best Practices:**\n• Only use for trusted CI/CD agents\n• Consider Docker-in-Docker for isolation\n• Use in isolated environments only\n• Alternative: Kubernetes with restricted RBAC"
  },
  {
    "id": 10,
    "text": "How do you optimize a Node.js Dockerfile to reduce build time and image size?",
    "explanation": "Leverage Docker's build cache by separating dependency installation from application code.\n\n**❌ Problematic:**\n```dockerfile\nFROM node:18-alpine\nWORKDIR /app\nCOPY . .          # Every code change invalidates cache\nRUN npm install   # Reinstalls deps unnecessarily\nCMD [\"node\", \"server.js\"]\n```\n\n**✅ Optimized:**\n```dockerfile\nFROM node:18-alpine\nWORKDIR /app\n\n# Copy package files first (cached layer)\nCOPY package*.json ./\nRUN npm install --omit=dev\n\n# Copy app code last (rebuilds only when code changes)\nCOPY . .\nEXPOSE 3000\nCMD [\"node\", \"server.js\"]\n```\n\n**Key Benefits:**\n• **Faster rebuilds** - npm install only runs when dependencies change\n• **Smaller images** - `--omit=dev` excludes dev dependencies\n• **Better caching** - Dependencies cached separately from app code\n\n**Layer Strategy:**\n1. Base image + workdir\n2. Package files + npm install (cached)\n3. Application code (rebuilds as needed)"
  },
  {
    "id": 11,
    "text": "How do you manage different environment configurations in Docker Compose?",
    "explanation": "Docker Compose allows you to use **multiple Compose files** to extend and override configurations. This is ideal for managing environment-specific settings.\n\n**File Structure:**\n```\n. # Project root\n├── docker-compose.yml      # Base configuration (common to all environments)\n├── docker-compose.override.yml # Default override for local dev (Docker Compose auto-loads this)\n├── docker-compose.prod.yml   # Production-specific overrides\n├── docker-compose.staging.yml # Staging-specific overrides\n└── app/\n    ├── Dockerfile\n    └── ...\n```\n\n**`docker-compose.yml` (Base - common config):**\n```yaml\nversion: '3.8'\nservices:\n  web:\n    build: ./app\n    image: myapp:${TAG:-latest} # Use a build argument or environment variable for tag\n    environment:\n      APP_ENV: development # Default for development\n    networks:\n      - app_net\n  db:\n    image: postgres:13\n    environment:\n      POSTGRES_DB: myapp_dev\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n    volumes:\n      - db_data:/var/lib/postgresql/data\n    networks:\n      - app_net\n\nnetworks:\n  app_net:\n\nvolumes:\n  db_data:\n```\n\n**`docker-compose.prod.yml` (Production Overrides):**\n```yaml\nversion: '3.8'\nservices:\n  web:\n    # Override environment variable\n    environment:\n      APP_ENV: production\n      DB_HOST: production-db-hostname # Or use a different network/service name\n    ports:\n      - \"80:80\" # Expose production port\n    deploy: # Production specific deployment configs (e.g., replicas, restart policy)\n      replicas: 3\n      restart_policy:\n        condition: on-failure\n  db:\n    # Use a different image or external database for production\n    image: postgres:13-alpine # Smaller image for prod\n    volumes:\n      - prod_db_data:/var/lib/postgresql/data # Different volume for prod data\n\nvolumes:\n  prod_db_data:\n```\n\n**How to use:**\n\n1.  **For local development (auto-loads `docker-compose.override.yml`):**\n    ```bash\n    docker compose up -d\n    ```\n\n2.  **For production deployment:** Explicitly specify the base and production override files:\n    ```bash\n    docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n    ```\n    *Note: The last file specified takes precedence for overlapping configurations.* \n    You can also combine this with environment variables for the image tag:\n    ```bash\n    TAG=1.0.0 docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n    ```\n\n**Flowchart (Text-based):**\n```\n[Start Multi-Environment Docker Compose]\n       |\n       V\n[1. Create `docker-compose.yml` for base/common config]\n       |\n       V\n[2. Create environment-specific override files (e.g., `docker-compose.prod.yml`)]\n       |\n       +--- (Each override file defines changes/additions for that environment) ---\n       |\n       V\n[3. To deploy a specific environment, use `-f` flag for each file]\n       |\n       +--- (Example: `docker compose -f base.yml -f prod.yml up`) ---\n       |\n       V\n[End Multi-Environment Setup]\n```"
  },
  {
    "id": 12,
    "text": "How do you debug a container that starts but immediately exits with no logs?",
    "explanation": "This is a common symptom of the container's main process crashing immediately, or the `CMD`/`ENTRYPOINT` not being configured correctly, or an underlying runtime issue. No log output suggests the process might not even get to the point of writing to stdout/stderr, or it's logging elsewhere.\n\n**Diagnosis Flow (Text-based):**\n```\n[Container Exits Immediately with Non-Zero Status]\n       |\n       V\n[1. Check 'docker logs <container_name>']\n       |\n       +--- Any output? ---\n       |   +--- YES -> Analyze logs for errors\n       |   +--- NO  -> Proceed to step 2\n       |\n       V\n[2. Inspect Container Exit Code (docker inspect <container_name> | grep 'ExitCode')]\n       |\n       +--- Exit code tells you *what* failed (0=success, non-0=failure). Look up common codes if specific.\n       |\n       V\n[3. Run container in interactive mode with overridden CMD/ENTRYPOINT]\n       |\n       +--- (e.g., 'docker run -it my-image bash' or 'sh') ---\n       |           |\n       |           V\n       |   [Once inside shell, manually run the application's intended startup command]\n       |           |\n       |           V\n       |   [Observe immediate errors/output in the shell]\n       |\n       V\n[4. Verify Dockerfile's CMD/ENTRYPOINT]\n       |\n       +--- (Is it correct? Using exec vs shell form correctly? Are paths valid?) ---\n       |\n       V\n[5. Check File Permissions inside container for the startup script/binary]\n       |\n       +--- (e.g., 'ls -l /path/to/script' inside 'docker exec' session) ---\n       |\n       V\n[6. Check for Missing Dependencies or Environment Variables]\n       |\n       +--- (The app might be missing runtime libraries or required ENV vars at startup) ---\n       |\n       V\n[7. Examine Host Kernel/Docker Daemon Logs (if OS-level crash suspected)]\n       |\n       +--- (Less common, but possible for low-level issues) ---\n       |\n       V\n[End Diagnosis]\n```\n\n**Common Causes:**\n1.  **Incorrect `CMD`/`ENTRYPOINT`:** The command specified to run the application either doesn't exist, has incorrect arguments, or isn't executable.\n2.  **Missing Dependencies/Libraries:** The application expects a library or dependency that isn't present in the image (especially common with `alpine` base images).\n3.  **File Permissions:** The main executable or a crucial configuration file doesn't have the correct read/execute permissions inside the container.\n4.  **Application Configuration Error:** The application itself immediately fails due to an invalid configuration (e.g., incorrect database URL, missing API key).\n5.  **Out of Memory (OOM) at Startup:** If the application has a very high memory footprint, Docker's OOM killer might terminate it immediately if insufficient memory is available or allocated.\n\n**Example Diagnosis Steps & Commands:**\n1.  **Check `docker ps -a`:** Note the `STATUS` column; it will likely show `Exited (X) Y seconds ago` where `X` is the non-zero exit code.\n    ```bash\n    docker ps -a\n    ```\n2.  **Run interactively:** The most effective step.\n    ```bash\n    docker run -it --rm my-failing-image /bin/bash\n    # Once inside the bash shell, try to manually run your app's startup command\n    # e.g., if CMD was 'node server.js':\n    # node server.js\n    # If CMD was './startup.sh':\n    # ./startup.sh\n    # This will often reveal the exact error that caused the crash.\n    ```\n3.  **Check Dockerfile `CMD`/`ENTRYPOINT`**: Ensure paths are correct and binaries exist."
  },
  {
    "id": 13,
    "text": "How do you create debug and production versions from the same Dockerfile?",
    "explanation": "Multi-stage builds are perfect for this. You'll define distinct stages for building, debugging, and the final production image, and then use the `--target` flag during `docker build` to select which stage to build up to.\n\n**`Dockerfile` Example:**\n```dockerfile\n# syntax=docker/dockerfile:1.4 # Required for named stages and build targets\n\n# Stage 1: Base Build Environment (e.g., for Go, Java, C++)\nFROM golang:1.20 AS builder\nWORKDIR /app\nCOPY . .\nRUN go mod tidy\nRUN CGO_ENABLED=0 GOOS=linux go build -o myapp .\n\n# Stage 2: Debug Build Environment\nFROM golang:1.20 AS debug-builder # Use a full image to preserve debugging symbols\nWORKDIR /app\nCOPY . .\nRUN go mod tidy\n# Build without stripping symbols or with debug flags\nRUN go build -o myapp-debug -gcflags=\"all=-N -l\" .\n\n# Stage 3: Debug Image (includes runtime and debug tools)\nFROM debian:stable-slim AS debug-image\nWORKDIR /app\nCOPY --from=debug-builder /app/myapp-debug .\n# Add debug tools like strace, gdb, or even a shell if needed\nRUN apt-get update && apt-get install -y strace curl && rm -rf /var/lib/apt/lists/*\nEXPOSE 8080\nENTRYPOINT [\"./myapp-debug\"]\n\n# Stage 4: Production Image (minimal)\nFROM alpine:latest AS production-image\nWORKDIR /app\nCOPY --from=builder /app/myapp .\nEXPOSE 8080\nENTRYPOINT [\"./myapp\"]\n```\n\n**How to Build & Use:**\n\n1.  **To build the production image (default behavior):**\n    ```bash\n    docker build -t my-app:production .\n    # This automatically builds up to the last FROM stage (production-image)\n    ```\n\n2.  **To build the debug image:**\n    ```bash\n    docker build --target debug-image -t my-app:debug .\n    ```\n\n**Explanation & Flowchart (Text-based):**\n```\n[Start Docker Build Process]\n       |\n       V\n[Parse Dockerfile]\n       |\n       V\n[Does 'docker build' command include '--target <stage_name>'?]\n       |\n       +--- NO (default build) ---\n       |           V\n       |   [Builds ALL stages up to the LAST 'FROM' instruction]\n       |           |\n       |           V\n       |   [Final image is 'production-image' (minimal)]\n       |\n       +--- YES (e.g., --target debug-image) ---\n                   V\n           [Builds ALL stages that the specified target stage DEPENDS ON]\n                   |\n                   V\n           [Final image is 'debug-image' (includes tools, unstripped binary)]\n```\n\n**Benefits:**\n* **Single Source of Truth:** One Dockerfile manages all build variations.\n* **Image Size Control:** Production images remain small, while debug images can be larger for introspection.\n* **Clear Separation:** Build steps for different purposes are logically separated."
  },
  {
    "id": 14,
    "text": "How do you troubleshoot network connectivity issues between Docker Compose services?",
    "explanation": "This indicates a potential networking configuration issue or a DNS resolution problem within the Docker network.\n\n**Diagnosis Flow (Text-based):**\n```\n[Start Network Troubleshooting]\n       |\n       V\n[1. Verify containers are running and on the same network]\n       |- Use 'docker ps' to confirm both are up.\n       |- Use 'docker inspect <container_id>' to check 'Networks' section.\n       |\n       V\n[2. Access web container's shell (docker exec -it web bash)]\n       |\n       V\n[3. Ping the API service name from within the web container]\n       |- 'ping api' (if ping is installed)\n       |\n       +--- Ping successful? ---\n       |   +--- YES -> Network is fine, issue is app-level (e.g., port, config, firewall)\n       |   +--- NO  -> Proceed to step 4\n       |\n       V\n[4. Check API container's exposed port]\n       |- Is the 'api' app listening on the expected port inside its container?\n       |- (e.g., 'docker exec api netstat -tulnp' or 'ss -tulnp')\n       |\n       V\n[5. Check Docker Compose network definition]\n       |- Are both services explicitly listed under the same network in docker-compose.yml?\n       |- Is the network driver 'bridge' (default and allows service name resolution)?\n       |\n       V\n[6. Restart services or rebuild (if network config changed)]\n       |- 'docker compose restart' or 'docker compose down && docker compose up'\n       |\n       V\n[End Network Troubleshooting]\n```\n\n**Example Commands for Diagnosis:**\n\n1.  **Verify Containers and Networks:**\n    ```bash\n    docker ps\n    docker inspect web | grep -A 5 -E 'Networks|Name'\n    docker inspect api | grep -A 5 -E 'Networks|Name'\n    docker network ls\n    docker network inspect <your_compose_project_network> # Check containers attached\n    ```\n    *Look for both containers listed under the same bridge network generated by Docker Compose (e.g., `<project_name>_default` or a custom network you defined).* \n\n2.  **Access `web` container and test connectivity:**\n    ```bash\n    docker exec -it web bash\n    # Inside the web container:\n    # ping api                  # Check basic network connectivity by name\n    # curl http://api:8080/health # Check if service is listening on expected port (replace 8080 with actual port)\n    # exit\n    ```\n    *If `ping` fails, it's a DNS or network isolation issue. If `ping` works but `curl` fails, the `api` service might not be listening on the expected port or path.* \n\n3.  **Check `api` service's listening ports:**\n    ```bash\n    docker exec -it api netstat -tulnp # (requires net-tools or iproute2 installed in container)\n    ```\n    *Confirm the application inside the `api` container is actually listening on the port the `web` container is trying to connect to.* \n\n4.  **Review `docker-compose.yml`:**\n    Ensure both `web` and `api` services are part of the same network, typically the default one created by Compose, or a named one explicitly defined.\n    ```yaml\n    version: '3.8'\n    services:\n      web:\n        # ...\n        networks:\n          - my_app_network\n\n      api:\n        # ...\n        networks:\n          - my_app_network\n\n    networks:\n      my_app_network:\n        driver: bridge # This is the default and allows service name resolution\n    ```\n\nBy following these steps, you can pinpoint whether the issue lies in network configuration, DNS resolution, or the application's readiness/listening port."
  },
  {
    "id": 15,
    "text": "How do you force delete a Docker image that's in use or has dependencies?",
    "explanation": "Docker prevents deletion of images that are in use or that have child images based on them to prevent breaking dependencies. To force deletion, you need to address the dependencies first.\n\n**Diagnosis & Deletion Flow (Text-based):**\n```\n[Start Image Deletion Problem]\n       |\n       V\n[1. Try 'docker rmi <image_id_or_name>']\n       |\n       +--- Fails with 'in use by running container'? ---\n       |               |\n       |               V\n       |       [2. Stop and remove the running container]\n       |               |- 'docker stop <container_id>'\n       |               |- 'docker rm <container_id>'\n       |               |\n       |               V\n       |       [Retry 'docker rmi']\n       |\n       +--- Fails with 'image has dependent children'? ---\n                       |\n                       V\n               [3. List all images and identify child images]\n                       |- 'docker images --filter \"ancestor=<image_id>\"'\n                       |\n                       V\n               [4. Remove ALL child images first (recursive deletion usually not supported directly)]\n                       |- 'docker rmi <child_image_id>'\n                       |\n                       V\n               [5. Then, remove the parent image]\n                       |- 'docker rmi <parent_image_id>'\n                       |\n                       V\n               [Consider 'docker system prune -a' for a more aggressive cleanup of all unused resources]\n```\n\n**Commands to use:**\n\n1.  **Identify running containers using the image:**\n    ```bash\n    docker ps -a --filter ancestor=my-image:latest\n    ```\n    *This will show you any containers, running or stopped, that were created from `my-image:latest`.* \n\n2.  **Stop and remove those containers:**\n    ```bash\n    docker stop $(docker ps -a -q --filter ancestor=my-image:latest)\n    docker rm $(docker ps -a -q --filter ancestor=my-image:latest)\n    ```\n\n3.  **Identify child images:**\n    If the error is about 'dependent children', it means other images were built on top of the one you're trying to delete.\n    ```bash\n    # Get the ID of the image you want to delete\n    docker images --filter reference=my-base-image:1.0 --format \"{{.ID}}\"\n\n    # Then, find images that use it as a parent (replace <IMAGE_ID> with the actual ID)\n    docker images --filter \"ancestor=<IMAGE_ID>\"\n    ```\n    *You'll need to remove these 'child' images first before you can remove the parent image.* \n\n4.  **Force remove an image (use with extreme caution!):**\n    If you are absolutely sure you want to remove an image and all containers/children dependent on it, you can use the force flag, but it's generally not recommended without understanding implications.\n    ```bash\n    docker rmi -f my-image:latest\n    ```\n\n5.  **Comprehensive Cleanup:** For a general cleanup of unused images (including dangling and unused ones), stopped containers, and networks:\n    ```bash\n    docker system prune -a\n    ```\n    *This is often the easiest solution if you just want to clear out everything not actively in use.*"
  },
  {
    "id": 16,
    "text": "How do you set up hot-reload development environment with Docker Compose?",
    "explanation": "This scenario calls for a **bind mount**, which links a directory from your host machine directly into the container. Changes made on the host are immediately reflected inside the container.\n\n**`docker-compose.yml` example:**\n```yaml\nversion: '3.8'\nservices:\n  web:\n    build:\n      context: .\n      dockerfile: ./app/Dockerfile\n    ports:\n      - \"3000:3000\"\n    volumes:\n      # Bind mount the local 'app' directory to '/app' inside the container\n      - ./app:/app\n      # Optional: if node_modules are installed in the container, mount an anonymous volume\n      # over it to prevent host's node_modules interfering (Windows/macOS often need this)\n      - /app/node_modules # Anonymous volume over /app/node_modules\n    environment:\n      NODE_ENV: development\n    command: npm run dev # Assuming your app has a dev script with hot-reloading\n```\n\n**Explanation:**\n1.  **`volumes: - ./app:/app`**: This is the bind mount. `.` refers to the directory where your `docker-compose.yml` resides. `./app` is the path on your host, and `/app` is the path inside the container.\n2.  **`command: npm run dev`**: Your application inside the container needs to have a development server or a watcher (like `nodemon` for Node.js, `flask run --reload` for Flask) that automatically reloads or restarts the application when file changes are detected.\n3.  **`volumes: - /app/node_modules` (Anonymous Volume - important for some OS/app types)**:\n    * On Windows and macOS, bind mounts from the host can sometimes have performance issues or permission problems with high I/O operations (like `npm install`).\n    * If your `npm install` runs *inside* the container, the `node_modules` directory will be created there. If you bind-mount `/app` from the host, the `node_modules` on the host (if it exists) might interfere or performance might be poor.\n    * By adding `- /app/node_modules` (an anonymous volume, just a path), you tell Docker to mount a *separate volume* specifically at `/app/node_modules` inside the container. This effectively *hides* the `node_modules` directory from the host's bind mount, ensuring that `npm install` runs entirely within a Docker volume, which is usually faster and more reliable.\n\n**Flowchart (Text-based):**\n```\n[Start Dev Setup]\n       |\n       V\n[1. Create basic `docker-compose.yml` and Dockerfile]\n       |\n       V\n[2. Identify application's source code directory on host]\n       |\n       V\n[3. Add bind mount to `volumes` section of service in `docker-compose.yml`]\n       |- Syntax: `- <host_path>:<container_path>`\n       |\n       V\n[4. (Conditional: For Node.js/Python/similar on Windows/macOS with local dependencies)\n   Add anonymous volume for dependency directory (e.g., `- /app/node_modules`)]\n       |\n       V\n[5. Ensure container's CMD/Entrypoint includes a watcher/hot-reload command]\n       |\n       V\n[Test: Make a code change on host, verify app reloads in container]\n       |\n       V\n[End Dev Setup]\n```"
  },
  {
    "id": 17,
    "text": "How do you debug a Docker Compose service that keeps restarting?",
    "explanation": "When a service restarts too quickly, `docker compose logs` might not show the initial crash, or the error might be obscured. You need to temporarily modify the service's startup behavior to get an interactive shell to debug.\n\n**Diagnosis Flow (Text-based):**\n```\n[Service Frequently Restarts]\n       |\n       V\n[1. Check 'docker compose logs <service_name>' for immediate clues]\n       |\n       +--- No clear error? ---\n       |\n       V\n[2. Temporarily modify 'docker-compose.yml' for the problematic service]\n       |- Override 'command' to an interactive shell (e.g., 'bash' or 'sh')\n       |- Remove 'restart' policy (or set to 'no')\n       |- Remove 'healthcheck' (if it's causing restarts)\n       |\n       V\n[3. Rebuild (if needed) and start ONLY that service]\n       |- 'docker compose up -d --no-deps <service_name>'\n       |\n       V\n[4. Get an interactive shell inside the running (but paused) service]\n       |- 'docker exec -it <container_name> bash' or 'sh'\n       |\n       V\n[5. Manually execute the original startup command/script inside the shell]\n       |- Observe errors directly in the terminal\n       |\n       V\n[6. Debug/Fix configuration issue]\n       |\n       V\n[7. Revert 'docker-compose.yml' changes, rebuild, and restart normally]\n       |\n       V\n[End Diagnosis]\n```\n\n**Example `docker-compose.yml` modification:**\n\n**Original (problematic):**\n```yaml\nservices:\n  my-app:\n    image: my-app-image\n    restart: always\n    command: [\"node\", \"/app/src/index.js\"]\n    # healthcheck: # May also be present and cause restarts\n    #   test: [\"CMD\", \"curl\", \"http://localhost:3000/health\"]\n```\n\n**Modified for Debugging:**\n```yaml\nservices:\n  my-app:\n    image: my-app-image\n    restart: \"no\" # Crucial: prevent automatic restarts\n    command: [\"bash\"] # Override to an interactive shell\n    # healthcheck: # Temporarily comment out or remove this if present\n    #   test: [\"CMD\", \"curl\", \"http://localhost:3000/health\"]\n```\n\n**Steps:**\n1.  **Modify `docker-compose.yml`** as shown above.\n2.  **Bring up *only* the problematic service (without dependencies if they're complex):**\n    ```bash\n    docker compose up -d --no-deps my-app\n    ```\n    (The `--no-deps` prevents other services from restarting if they depend on `my-app` and might make debugging harder by introducing more changes).\n3.  **Get into the container's shell:**\n    ```bash\n    docker exec -it <container_name_of_my_app> bash\n    # (You can get the container name from 'docker ps')\n    ```\n4.  **Manually run the application's original command:**\n    ```bash\n    # Inside the container's bash shell:\n    node /app/src/index.js\n    ```\n    *This will now print any errors directly to your terminal, allowing you to see exactly why the application is failing at startup.* \n5.  **Fix the issue** (e.g., correct a path, environment variable, or missing file).\n6.  **Revert the `docker-compose.yml` changes**.\n7.  **Bring down and then up your services normally:**\n    ```bash\n    docker compose down\n    docker compose up -d\n    ```"
  },
  {
    "id": 18,
    "text": "How do you fix nginx container permission issues with mounted volumes?",
    "explanation": "This is a common permissions issue when bind-mounting volumes from the host. The process inside the container (e.g., `nginx`) runs as a specific user (often `nginx` or `www-data`), but the directory on the host often has permissions for your host user, not matching the container's user.\n\n**Diagnosis & Solution Flow (Text-based):**\n```\n[Nginx (or other non-root app) cannot write to mounted volume]\n       |\n       V\n[1. Check 'docker inspect <container_id>' for User/UID/GID info (HostConfig.User)]\n       |\n       V\n[2. Get interactive shell into the container]\n       |- 'docker exec -it <container_name> bash'\n       |\n       V\n[3. Inside container: Check the UID/GID of the user running Nginx]\n       |- 'id nginx' or 'id www-data'\n       |- 'ps aux | grep nginx' to see the user/process running\n       |\n       V\n[4. Inside container: Check permissions of the mounted volume path]\n       |- 'ls -l /path/to/mounted/volume'\n       |\n       V\n[5. On Host: Adjust permissions of the host directory that is bind-mounted]\n       |- Option A (Recommended): Change ownership of host directory to match container's UID/GID.\n       |- Option B (Less secure): Set broad write permissions (e.g., chmod 777).\n       |\n       V\n[6. Restart container or rebuild image if user/group changes were made in Dockerfile]\n       |\n       V\n[End Troubleshooting]\n```\n\n**Example Solution using Host Permissions:**\n\nLet's assume the `nginx` user inside the container has `UID=101` and `GID=101` (common for Nginx/Alpine).\n\n1.  **Find the UID/GID of the `nginx` user inside the container:**\n    * Run a temporary container and get into its shell:\n        ```bash\n        docker run --rm -it nginx:alpine sh\n        ```\n    * Inside the container, run:\n        ```bash\n        id nginx\n        # Example Output: uid=101(nginx) gid=101(nginx) groups=101(nginx)\n        ```\n    * So, the `nginx` process runs as `UID 101` and `GID 101`.\n\n2.  **On your host machine, create the directory and set its permissions to match the container's `UID/GID`:**\n    Assuming your data directory on the host is `./nginx-data`:\n    ```bash\n    mkdir -p ./nginx-data\n    sudo chown -R 101:101 ./nginx-data # Set ownership to UID 101, GID 101\n    sudo chmod 775 ./nginx-data       # Ensure group has write permission\n    ```\n\n3.  **Run your container, mounting this directory:**\n    ```bash\n    docker run -d -p 80:80 -v ./nginx-data:/var/www/html --name my-nginx nginx:alpine\n    ```\n    Now, the `nginx` process inside the container, running as `UID 101`, will have the necessary permissions to write."
  }
]
  },
  "user": {
    "uid": "static-user",
    "email": "static@example.com",
    "name": "Static User",
    "emailVerified": true
  }
}
